{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wildfire and Drought Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Data\n",
    "\n",
    "  - &#x2611; Download [wildfire Sqlite DB](https://www.kaggle.com/rtatman/188-million-us-wildfires) from Kaggle\n",
    "  - &#x2611; Download [drought soil and weather CSVs](https://www.kaggle.com/cdminix/us-drought-meteorological-data) from Kaggle\n",
    "  - &#x2611; Import soil and weather CSVs into Sqlite\n",
    "  - &#x2611; Remove non-California data to keep the dataset more focused\n",
    "  - &#x2611; Remove wildfire and soil/weather data that does not overlap\n",
    "  - &#x2611; Load in county FIPS codes and geospatial lat/long into Sqlite\n",
    "  - Add indexes/foreign keys to speed up Sqlite\n",
    "    - &#x2611; year\n",
    "    - &#x2611; fips\n",
    "    - &#x2611; long/lat on fires and soil\n",
    "  - &#x2611; Truncate Latitude and Longitude to 11 km (1 decimal place)\n",
    "  - &#x2611; Backfill FIPS_CODE for fire using long/lat (maybe?)\n",
    "  - Weather by date and long/lat between 2000-01-01 and 2015-12-31 from NASA Power API\n",
    "  - &#x2611; Drought score by date and FIPS county between 2000-01-01 and 2015-12-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas\n",
    "!pip install -q pysqlite3\n",
    "!pip install -q requests\n",
    "!pip install -q shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import sqlite3\n",
    "import shapely.wkt\n",
    "from shapely.geometry import Point\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### California Counties\n",
    "\n",
    "1. Scrape Wikipedia for the Unites States counties from Wikipedia.\n",
    "2. Filter out non-California counties.\n",
    "3. Truncate longitude and latitude to 1 decimal place (~11 km wide). This should make the analysis go faster and also better generalize the location of predicted fires fires.\n",
    "4. Join the Wikipedia county data with the Geographic boundies data for each California county. The Geographic boundaries data is in the form of `MULTIPOLYGON (((` tuples that can be interpreted by the shapely python package.\n",
    "5. Set the index of the county DataFrame to FIPS which is the unique identifier for each county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       latitude   longitude   lat   long       name  \\\n",
      "FIPS                                                  \n",
      "6001  37.648081 -121.913304  37.6 -121.9    Alameda   \n",
      "6003  38.617610 -119.798999  38.6 -119.8     Alpine   \n",
      "6005  38.443550 -120.653856  38.4 -120.7     Amador   \n",
      "6007  39.665959 -121.601919  39.7 -121.6      Butte   \n",
      "6009  38.187844 -120.555115  38.2 -120.6  Calaveras   \n",
      "\n",
      "                                       geo_multipolygon  \n",
      "FIPS                                                     \n",
      "6001  MULTIPOLYGON (((-122.3110971410252 37.86340197...  \n",
      "6003  MULTIPOLYGON (((-119.93538249202298 38.8084818...  \n",
      "6005  MULTIPOLYGON (((-120.25874105290194 38.5799975...  \n",
      "6007  MULTIPOLYGON (((-121.6354363647807 40.00088422...  \n",
      "6009  MULTIPOLYGON (((-120.2108859831663 38.50000349...  \n"
     ]
    }
   ],
   "source": [
    "county_df = pd.read_html('https://en.wikipedia.org/wiki/User:Michael_J/County_table')[0]\n",
    "float_degrees = lambda x: float(x.replace('°','').replace('–','-'))\n",
    "county_df['latitude'] = county_df['Latitude'].apply(float_degrees)\n",
    "county_df['longitude'] = county_df['Longitude'].apply(float_degrees)\n",
    "county_df['lat'] = round(county_df['latitude'], 1)\n",
    "county_df['long'] = round(county_df['longitude'], 1)\n",
    "county_df['name'] = county_df['County [2]']\n",
    "\n",
    "county_df = county_df[county_df['State'] == 'CA']\n",
    "county_df = county_df.loc[:, county_df.columns.intersection(['FIPS', 'name', 'latitude', 'longitude', 'lat', 'long'])]\n",
    "\n",
    "# Downloaded from https://data.edd.ca.gov/api/views/bpwh-bcb3/rows.csv?accessType=DOWNLOAD\n",
    "county_geo_df = pd.read_csv('./county_geospatial.csv')\n",
    "county_geo_df = county_geo_df.loc[:, county_geo_df.columns.intersection(['name', 'geo_multipolygon'])]\n",
    "\n",
    "county_df = pd.merge(county_df, county_geo_df, left_on='name', right_on='name')\n",
    "county_df = county_df.set_index('FIPS')\n",
    "\n",
    "print(county_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the counties DataFrame into Sqlite to make joins and analysis using SQL easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('/Users/eerichmo/Documents/fires.sqlite')\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('DROP TABLE county')\n",
    "cur.execute('''CREATE TABLE county (\n",
    "\tfips\t  \t\t\t\t\tINTEGER NOT NULL,\n",
    "\tname\t  \t\t\t\t\tTEXT NOT NULL,\n",
    "\tlatitude \t\t\t\t\tREAL NOT NULL,\n",
    "\tlongitude\t\t\t\t\tREAL NOT NULL,\n",
    "\tlat\t    \t\t\t\t\tREAL NOT NULL,\n",
    "\tlong\t  \t\t\t\t\tREAL NOT NULL,\n",
    "\tgeo_multipolygon\tTEXT NOT NULL,\n",
    "\tPRIMARY KEY(fips)\n",
    ");''')\n",
    "\n",
    "county_df.to_sql('county', conn, if_exists='append')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the Goegraphic boundaries for California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California bounds (east-south, west-north): (-116.10618166434291, 32.53402817678555, -123.51814169611895, 42.009834867689875)\n"
     ]
    }
   ],
   "source": [
    "ca_bounds = [-180, 90, 180, -90]\n",
    "\n",
    "for i, county in county_df.iterrows():\n",
    "  name = county['name']\n",
    "  geo = shapely.wkt.loads(county['geo_multipolygon'])\n",
    "\n",
    "  # East\n",
    "  if (geo.bounds[0] > ca_bounds[0]):\n",
    "    ca_bounds[0] = geo.bounds[0]\n",
    "\n",
    "  # South\n",
    "  if (geo.bounds[1] < ca_bounds[1]):\n",
    "    ca_bounds[1] = geo.bounds[1]\n",
    "\n",
    "  # West\n",
    "  if (geo.bounds[2] < ca_bounds[2]):\n",
    "    ca_bounds[2] = geo.bounds[2]\n",
    "\n",
    "  # Norht\n",
    "  if (geo.bounds[3] > ca_bounds[3]):\n",
    "    ca_bounds[3] = geo.bounds[3]\n",
    "\n",
    "ca_bounds = tuple(ca_bounds)\n",
    "print(f'California bounds (east-south, west-north): {ca_bounds}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the Sqlite `fires` table to help future analysis.\n",
    "1. Rename `fips_code` to `fips`.\n",
    "2. Truncate `longitude` and `latitude` into 1 decimal place `long` and `lat` columns respectively.\n",
    "3. Add an index on `date`, `long`, and `lat` to help speed up the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('/Users/eerichmo/Documents/fires.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('UPDATE fires SET fips = fips_code WHERE fips IS NULL')\n",
    "cur.execute('UPDATE fires SET LONG = round(LONGITUDE, 1), LAT = round(LATITUDE, 1)')\n",
    "cur.execute(\"UPDATE fires SET date = strftime('%Y-%m-%d', discovery_date)\")\n",
    "\n",
    "cur.execute('DROP INDEX IF EXISTS idx_fires_date_long_lat')\n",
    "cur.execute('CREATE INDEX idx_fires_date_long_lat ON fires(date, long, lat)')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `weater_geo` table that holds the daily weather details at 11km wide longitude/latitude points between 1 Jan 2000 and 21 Dec 2015/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('/Users/eerichmo/Documents/fires.sqlite')\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# cur.execute('DROP TABLE IF EXISTS weather_geo')\n",
    "cur.execute('''CREATE TABLE weather_geo (\n",
    "\tdate\t\t\t\t\t\t\tTEXT NOT NULL,\n",
    "\tlong\t\t\t\t\t\t  REAL NOT NULL,\n",
    "\tlat\t\t\t\t\t\t\t  REAL NOT NULL,\n",
    "\tfips\t\t\t\t\t\t\tINTEGER NOT NULL,\n",
    "\tprecipitation\t\t\tREAL,\n",
    "\tpressure\t\t\t\t\tREAL,\n",
    "\thumidity_2m\t\t\t\tREAL,\n",
    "\ttemp_2m\t\t\t\t\t\tREAL,\n",
    "\ttemp_dew_point_2m\tREAL,\n",
    "\ttemp_wet_bulb_2m\tREAL,\n",
    "\ttemp_max_2m\t\t\t\tREAL,\n",
    "\ttemp_min_2m\t\t\t\tREAL,\n",
    "\ttemp_range_2m\t\t\tREAL,\n",
    "\ttemp_0m\t\t\t\t\t\tREAL,\n",
    "\twind_10m\t\t\t\t\tREAL,\n",
    "\twind_max_10m\t\t\tREAL,\n",
    "\twind_min_10m\t\t\tREAL,\n",
    "\twind_range_10m\t\tREAL,\n",
    "\twind_50m\t\t\t\t\tREAL,\n",
    "\twind_max_50m\t\t\tREAL,\n",
    "\twind_min_50m\t\t\tREAL,\n",
    "\twind_range_50m\t\tREAL,\n",
    "\tPRIMARY KEY(date, long, lat)\n",
    ");''')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WS10M_MIN', 'QV2M', 'T2M_RANGE', 'WS10M', 'T2M', 'WS50M_MIN', 'T2M_MAX', 'WS50M', 'TS', 'WS50M_RANGE', 'WS50M_MAX', 'WS10M_MAX', 'WS10M_RANGE', 'PS', 'T2MDEW', 'T2M_MIN', 'T2MWET', 'PRECTOT']\n"
     ]
    }
   ],
   "source": [
    "weather_params = [p.strip() for p in re.findall(\n",
    "\"^\\w+\",\n",
    "\"\"\"\n",
    "WS10M_MIN      MERRA2 1/2x1/2 Minimum Wind Speed at 10 Meters (m/s) \n",
    "QV2M           MERRA2 1/2x1/2 Specific Humidity at 2 Meters (g/kg) \n",
    "T2M_RANGE      MERRA2 1/2x1/2 Temperature Range at 2 Meters (C) \n",
    "WS10M          MERRA2 1/2x1/2 Wind Speed at 10 Meters (m/s) \n",
    "T2M            MERRA2 1/2x1/2 Temperature at 2 Meters (C) \n",
    "WS50M_MIN      MERRA2 1/2x1/2 Minimum Wind Speed at 50 Meters (m/s) \n",
    "T2M_MAX        MERRA2 1/2x1/2 Maximum Temperature at 2 Meters (C) \n",
    "WS50M          MERRA2 1/2x1/2 Wind Speed at 50 Meters (m/s) \n",
    "TS             MERRA2 1/2x1/2 Earth Skin Temperature (C) \n",
    "WS50M_RANGE    MERRA2 1/2x1/2 Wind Speed Range at 50 Meters (m/s) \n",
    "WS50M_MAX      MERRA2 1/2x1/2 Maximum Wind Speed at 50 Meters (m/s) \n",
    "WS10M_MAX      MERRA2 1/2x1/2 Maximum Wind Speed at 10 Meters (m/s) \n",
    "WS10M_RANGE    MERRA2 1/2x1/2 Wind Speed Range at 10 Meters (m/s) \n",
    "PS             MERRA2 1/2x1/2 Surface Pressure (kPa) \n",
    "T2MDEW         MERRA2 1/2x1/2 Dew/Frost Point at 2 Meters (C) \n",
    "T2M_MIN        MERRA2 1/2x1/2 Minimum Temperature at 2 Meters (C) \n",
    "T2MWET         MERRA2 1/2x1/2 Wet Bulb Temperature at 2 Meters (C) \n",
    "PRECTOT        MERRA2 1/2x1/2 Precipitation (mm day-1) \n",
    "\"\"\",\n",
    "re.MULTILINE\n",
    ")]\n",
    "\n",
    "print(weather_params)\n",
    "\n",
    "def fetch_weather(long, lat, start, end):\n",
    "    return requests.get(\n",
    "      'https://power.larc.nasa.gov/api/temporal/daily/point',\n",
    "      {\n",
    "          'parameters': ','.join(weather_params),\n",
    "          'community': 'SB',\n",
    "          'longitude': long,\n",
    "          'latitude': lat,\n",
    "          'start': start,\n",
    "          'end': end,\n",
    "          'format': 'JSON',\n",
    "      }\n",
    "    ).json()['properties']['parameter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colusa southwest to northeast: (38.9, -122.8) to (39.4, -121.8)\n",
      "Colusa at POINT (-122.7 39.3) took 6.1s\n",
      "Colusa at POINT (-122.6 39.3) took 5.6s\n",
      "Colusa at POINT (-122.5 39.2) took 68.1s\n",
      "Colusa at POINT (-122.5 39.3) took 5.2s\n",
      "Colusa at POINT (-122.4 39) took 5.0s\n",
      "Colusa at POINT (-122.4 39.1) took 65.6s\n",
      "Colusa at POINT (-122.4 39.2) took 5.6s\n",
      "Colusa at POINT (-122.4 39.3) took 5.2s\n",
      "Colusa at POINT (-122.3 39) took 5.5s\n",
      "Colusa at POINT (-122.3 39.1) took 6.0s\n",
      "Colusa at POINT (-122.3 39.2) took 5.7s\n",
      "Colusa at POINT (-122.3 39.3) took 65.6s\n",
      "Colusa at POINT (-122.2 39) took 5.6s\n",
      "Colusa at POINT (-122.2 39.1) took 65.7s\n",
      "Colusa at POINT (-122.2 39.2) took 7.5s\n",
      "Colusa at POINT (-122.2 39.3) took 5.5s\n",
      "Colusa at POINT (-122.1 39) took 5.6s\n",
      "Colusa at POINT (-122.1 39.1) took 5.1s\n",
      "Colusa at POINT (-122.1 39.2) took 9.1s\n",
      "Colusa at POINT (-122.1 39.3) took 5.6s\n",
      "Colusa at POINT (-122 39) took 125.8s\n",
      "Colusa at POINT (-122 39.1) took 125.6s\n",
      "Colusa at POINT (-122 39.2) took 5.5s\n",
      "Colusa at POINT (-122 39.3) took 5.6s\n",
      "Colusa at POINT (-121.9 39) took 125.9s\n",
      "Colusa at POINT (-121.9 39.1) took 6.1s\n"
     ]
    }
   ],
   "source": [
    "start_date = '20000101'\n",
    "end_date = '20151231'\n",
    "\n",
    "conn = sqlite3.connect('/Users/eerichmo/Documents/fires.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('SELECT fips FROM county WHERE fips NOT IN (SELECT DISTINCT fips FROM weather_geo) LIMIT 1')\n",
    "\n",
    "for row in cur.fetchall():\n",
    "  fips = row[0]\n",
    "  county = county_df.loc[fips]\n",
    "\n",
    "  name = county['name']\n",
    "  geo = shapely.wkt.loads(county['geo_multipolygon'])\n",
    "\n",
    "  long_min = round(geo.bounds[0], 1)\n",
    "  long_max = round(geo.bounds[2], 1)\n",
    "\n",
    "  lat_min = round(geo.bounds[1], 1)\n",
    "  lat_max = round(geo.bounds[3], 1)\n",
    "\n",
    "  print(f'{name} southwest to northeast: ({lat_min}, {long_min}) to ({lat_max}, {long_max})')\n",
    "\n",
    "  for long in range(int(long_min * 10), int(long_max * 10)):\n",
    "    for lat in range(int(lat_min * 10), int(lat_max * 10)):\n",
    "      point = Point(long / 10, lat / 10)\n",
    "      start = time.time()\n",
    "\n",
    "      if geo.contains(point):\n",
    "        json = fetch_weather(point.x, point.y, start_date, end_date)\n",
    "\n",
    "        for date in json['TS'].keys():\n",
    "          cur.execute('''\n",
    "            INSERT INTO weather_geo (\n",
    "              date, long, lat, fips, precipitation, pressure, humidity_2m, temp_2m,\n",
    "              temp_dew_point_2m, temp_wet_bulb_2m, temp_max_2m, temp_min_2m, temp_range_2m,\n",
    "              temp_0m, wind_10m, wind_max_10m, wind_min_10m, wind_range_10m, wind_50m,\n",
    "              wind_max_50m, wind_min_50m, wind_range_50m\n",
    "            )\n",
    "            VALUES (\n",
    "              :date, :long, :lat, :fips, :precipitation, :pressure, :humidity_2m, :temp_2m,\n",
    "              :temp_dew_point_2m, :temp_wet_bulb_2m, :temp_max_2m, :temp_min_2m, :temp_range_2m,\n",
    "              :temp_0m, :wind_10m, :wind_max_10m, :wind_min_10m, :wind_range_10m, :wind_50m,\n",
    "              :wind_max_50m, :wind_min_50m, :wind_range_50m\n",
    "            )\n",
    "            ''', {\n",
    "              'date': f'{date[0:4]}-{date[4:6]}-{date[6:8]}',\n",
    "              'long': point.x,\n",
    "              'lat': point.y,\n",
    "              'fips': fips,\n",
    "              'precipitation': json['PRECTOTCORR'][date],\n",
    "              'pressure': json['PS'][date],\n",
    "              'humidity_2m': json['QV2M'][date],\n",
    "              'temp_2m': json['T2M'][date],\n",
    "              'temp_dew_point_2m': json['T2MDEW'][date],\n",
    "              'temp_wet_bulb_2m': json['T2MWET'][date],\n",
    "              'temp_max_2m': json['T2M_MAX'][date],\n",
    "              'temp_min_2m': json['T2M_MIN'][date],\n",
    "              'temp_range_2m': json['T2M_RANGE'][date],\n",
    "              'temp_0m': json['TS'][date],\n",
    "              'wind_10m': json['WS10M'][date],\n",
    "              'wind_max_10m': json['WS10M_MAX'][date],\n",
    "              'wind_min_10m': json['WS10M_MIN'][date],\n",
    "              'wind_range_10m': json['WS10M_RANGE'][date],\n",
    "              'wind_50m': json['WS50M'][date],\n",
    "              'wind_max_50m': json['WS50M_MAX'][date],\n",
    "              'wind_min_50m': json['WS50M_MIN'][date],\n",
    "              'wind_range_50m': json['WS50M_RANGE'][date]\n",
    "            })\n",
    "\n",
    "        end = time.time()\n",
    "        print(f'{name} at {point} took {round(end - start, 1)}s')\n",
    "\n",
    "  conn.commit()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('/Users/eerichmo/Documents/fires.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('DROP TABLE IF EXISTS soil')\n",
    "cur.execute('''CREATE TABLE soil (\n",
    "\tlong\t\t\t\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\tlat\t\t\t\t\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\tfips\t\t\t\t\t\t\t\t\t\tINTEGER NOT NULL,\n",
    "\tlatitude\t\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\tlongitude\t\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\televation\t\t\t\t\t\t\t\tINTEGER NOT NULL,\n",
    "\tslope_005\t\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\tslope_005_02\t\t\t\t\t\tREAL NOT NULL,\n",
    "\tslope_02_05\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\tslope_05_10\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\tslope_10_15\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\tslope_15_30\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\tslope_30_45\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\tslope_45\t\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\taspect_north\t\t\t\t\t\tREAL NOT NULL,\n",
    "\taspect_east\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\taspect_south\t\t\t\t\t\tREAL NOT NULL,\n",
    "\taspect_west\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\taspect_unknown\t\t\t\t\tREAL NOT NULL,\n",
    "\twater_land\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\tbarren_land\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\turban_land\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\tgrass_land\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\tforest_land\t\t\t\t\t\t\tREAL NOT NULL,\n",
    "\tpartial_cultivated_land\tREAL NOT NULL,\n",
    "\tirrigated_land\t\t\t\t\tREAL NOT NULL,\n",
    "\tcultivated_land\t\t\t\t\tREAL NOT NULL,\n",
    "\tnutrient\t\t\t\t\t\t\t\tINTEGER NOT NULL,\n",
    "\tnutrient_retention\t\t\tINTEGER NOT NULL,\n",
    "\trooting\t\t\t\t\t\t\t\t\tINTEGER NOT NULL,\n",
    "\toxygen\t\t\t\t\t\t\t\t\tINTEGER NOT NULL,\n",
    "\texcess_salts\t\t\t\t\t\tINTEGER NOT NULL,\n",
    "\ttoxicity\t\t\t\t\t\t\t\tINTEGER NOT NULL,\n",
    "\tworkablity\t\t\t\t\t\t\tINTEGER NOT NULL\n",
    ")''')\n",
    "\n",
    "soil_df = pd.read_csv('./soil.csv')\n",
    "soil_df['lat'] = round(soil_df['latitude'], 1)\n",
    "soil_df['long'] = round(soil_df['longitude'], 1)\n",
    "\n",
    "soil_df = soil_df[soil_df['fips'].isin(county_df.index)]\n",
    "\n",
    "soil_df.to_sql('soil', conn, if_exists='append', index=False)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('/Users/eerichmo/Documents/fires.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('DROP TABLE IF EXISTS drought')\n",
    "cur.execute('''CREATE TABLE drought (\n",
    "  date          TEXT NOT NULL,\n",
    "  fips          INTEGER NOT NULL,\n",
    "  drought_score REAL,\n",
    "  PRIMARY KEY(date, fips)\n",
    ")''')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_drought(fips):\n",
    "    return requests.get(\n",
    "        'https://usdmdataservices.unl.edu/api/CountyStatistics/GetDroughtSeverityStatisticsByAreaPercent',\n",
    "        {\n",
    "            'aoi': fips,\n",
    "            'startdate': '10/1/1999',\n",
    "            'enddate': '12/31/2015',\n",
    "            'statisticsType': 1,\n",
    "        }\n",
    "    ).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetch drought score for 06023\n",
      "Fetch drought score for 06025\n",
      "Fetch drought score for 06027\n",
      "Fetch drought score for 06029\n",
      "Fetch drought score for 06031\n",
      "Fetch drought score for 06033\n",
      "Fetch drought score for 06035\n",
      "Fetch drought score for 06037\n",
      "Fetch drought score for 06039\n",
      "Fetch drought score for 06041\n",
      "Fetch drought score for 06043\n",
      "Fetch drought score for 06045\n",
      "Fetch drought score for 06047\n",
      "Fetch drought score for 06049\n",
      "Fetch drought score for 06051\n",
      "Fetch drought score for 06053\n",
      "Fetch drought score for 06055\n",
      "Fetch drought score for 06057\n",
      "Fetch drought score for 06059\n",
      "Fetch drought score for 06061\n",
      "Fetch drought score for 06063\n",
      "Fetch drought score for 06065\n",
      "Fetch drought score for 06067\n",
      "Fetch drought score for 06069\n",
      "Fetch drought score for 06071\n",
      "Fetch drought score for 06073\n",
      "Fetch drought score for 06075\n",
      "Fetch drought score for 06077\n",
      "Fetch drought score for 06079\n",
      "Fetch drought score for 06081\n",
      "Fetch drought score for 06083\n",
      "Fetch drought score for 06085\n",
      "Fetch drought score for 06087\n",
      "Fetch drought score for 06089\n",
      "Fetch drought score for 06091\n",
      "Fetch drought score for 06093\n",
      "Fetch drought score for 06095\n",
      "Fetch drought score for 06097\n",
      "Fetch drought score for 06099\n",
      "Fetch drought score for 06101\n",
      "Fetch drought score for 06103\n",
      "Fetch drought score for 06105\n",
      "Fetch drought score for 06107\n",
      "Fetch drought score for 06109\n",
      "Fetch drought score for 06111\n",
      "Fetch drought score for 06113\n",
      "Fetch drought score for 06115\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('/Users/eerichmo/Documents/fires.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('SELECT DISTINCT fips FROM drought WHERE drought_score IS NULL')\n",
    "\n",
    "for row in cur.fetchall():\n",
    "  fips = row[0]\n",
    "  fips_5_char = f'0{str(fips)}' if fips < 10000 else str(fips)\n",
    "\n",
    "  print(f'Fetch drought score for {fips_5_char}')\n",
    "  json = fetch_drought(fips_5_char)\n",
    "\n",
    "  for item in json:\n",
    "    drought_score = float(item['D0'])/100 + float(item['D1'])/100 + float(item['D2'])/100 + float(item['D3'])/100 + float(item['D4'])/100\n",
    "\n",
    "    # Backfill Jan 4 score to Jan 1-3 of 2000 as it seems to be missing\n",
    "    start = '2000-01-01' if item['ValidStart'] <= '2000-01-04' else item['ValidStart']\n",
    "\n",
    "    drought_params = { 'fips': fips, 'drought_score': drought_score, 'start': start, 'end': item['ValidEnd'] }\n",
    "    \n",
    "    cur.execute('''\n",
    "      UPDATE drought SET\n",
    "        drought_score = :drought_score\n",
    "      WHERE\n",
    "        fips = :fips AND date >= :start AND date <= :end\n",
    "    ''', drought_params)\n",
    "\n",
    "  conn.commit()\n",
    "  \n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('/Users/eerichmo/Documents/fires.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('SELECT longitude, latitude FROM fires WHERE fips IS NULL')\n",
    "\n",
    "for row in cur.fetchall():\n",
    "  long = row[0]\n",
    "  lat = row[1]\n",
    "\n",
    "  for fips, county in county_df.iterrows():\n",
    "    geo = shapely.wkt.loads(county['geo_multipolygon'])\n",
    "    point = Point(long, lat)\n",
    "\n",
    "    if geo.contains(point):\n",
    "      print(f'{point} is in {fips}')\n",
    "      cur.execute('''\n",
    "        UPDATE fires SET fips_code = :fips\n",
    "        WHERE longitude = :longitude AND latitude = :latitude\n",
    "      ''', { 'fips': fips, 'longitude': long, 'latitude': lat })\n",
    "      conn.commit()\n",
    "      break\n",
    "  \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Train-Split\n",
    "\n",
    "#### Splitting for 2000-2015\n",
    "\n",
    "- Train 2000-13 (13 years)\n",
    "- Validation 2013-14 (1 year)\n",
    "- Test 2014-15 (1 years)\n",
    "\n",
    "#### How to Process 13 years of data?\n",
    "\n",
    "- NN might allow batching\n",
    "- Regression models for 0% - 100% per long/lat grid (11 km^2)\n",
    "- Reduce long/lat km^2 over time (5 km^2)\n",
    "- Visualize with heatmap\n",
    "- Focus on origin long/lat\n",
    "\n",
    "#### Models\n",
    "\n",
    "1.  Linear\n",
    "2.  Random Forest Regression\n",
    "3.  ...any regression model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4885f37acae9217c235118400878352aafa7b76e66df698a1f601374f86939a7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('springboard': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
